
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Hadoop - My Octopress Blog</title>
  <meta name="author" content="windfire.cd">

  
  <meta name="description" content="简介 Apache Hadoop是一个开源的基于集群的分布式处理大数据的计算框架。
它用于将一个机器处理的问题切分为若干提供存储和计算资源的机器共同处理的问题，对于集群来说，
集群中的任何机器都可能失效，它提供基于应用层的异常处理功能。 Apache Hadoop项目分为三个子项目 [Hadoop &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://windfire-cd.github.com/blog/2012/07/05/hadoop/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="/javascripts/ender.js"></script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <link href="/atom.xml" rel="alternate" title="My Octopress Blog" type="application/atom+xml">
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  

</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">My Octopress Blog</a></h1>
  
    <h2>life and I</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:windfire-cd.github.com" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div>
<article class="hentry" role="article">
  
  <header>
    
      <h1 class="entry-title">Hadoop</h1>
    
    
      <p class="meta">
        








  


<time datetime="2012-07-05T18:14:00+08:00" pubdate data-updated="true">Jul 5<span>th</span>, 2012</time>
        
         | <a href="#disqus_thread">Comments</a>
        
      </p>
    
  </header>


<div class="entry-content"><h2>简介</h2>

<p><a href="http://hadoop.apache.org/">Apache Hadoop</a>是一个开源的基于集群的分布式处理大数据的计算框架。
它用于将一个机器处理的问题切分为若干提供存储和计算资源的机器共同处理的问题，对于集群来说，
集群中的任何机器都可能失效，它提供基于应用层的异常处理功能。</p>

<p><a href="http://hadoop.apache.org/">Apache Hadoop</a>项目分为三个子项目</p>

<ul>
<li>[Hadoop Common]</li>
</ul>


<p>hadoop主要克隆了Google运行系统的框架，包括</p>

<ul>
<li>文件系统HDFS</li>
<li>计算框架MapReduce</li>
<li>结构化数据处理HBase</li>
</ul>


<p>基于此的其他开源项目</p>

<ul>
<li>Pig</li>
<li>Zookeeper</li>
<li>HIVE</li>
</ul>


<p>大数据存储和访问</p>

<p>关系型数据库和MapReduce差异</p>

<p><strong>网格计算</strong></p>

<p>大规模分布式的主要问题是处理失效和错误</p>

<h2>MapReduce简介</h2>

<p>一种用于数据处理的编程模型，本质是并行的
分为两个阶段</p>

<ul>
<li>Map</li>
<li>Reduce</li>
</ul>


<p><strong>分支化</strong></p>

<ul>
<li>map任务</li>
<li>reduce任务</li>
</ul>


<p>两种类型节点控制作业执行</p>

<ul>
<li>jobtracker</li>
<li>tasktracker</li>
</ul>


<p><strong>输入输出流</strong></p>

<p><a href="http://hadoop.apache.org/">Apache Hadoop</a> 提供了API允许除JAVA外语言运行MapReduce，</p>

<h2>分布式文件系统</h2>

<h3>HDFS设计</h3>

<p>特点</p>

<ul>
<li>针对超大文件而设计的文件系统</li>
<li>流式数据访问</li>
<li>商用硬件</li>
</ul>


<p>缺点</p>

<ul>
<li>低延迟访问（如果需要低延迟HBase更好）</li>
<li>大量小文件</li>
<li>多用户写入，任意修改</li>
</ul>


<h3>HDFS概念</h3>

<p><strong>块</strong></p>

<ul>
<li>默认64M</li>
</ul>


<p><strong>名称节点和数据节点</strong></p>

<ul>
<li>管理者  命名空间</li>
<li>工作者  定位块</li>
</ul>


<p>命名空间损坏会造成系统失效，保证其可用有以下两种方式</p>

<ol>
<li>复制组成文件系统元数据的持久文件</li>
<li>二级名称节点</li>
</ol>


<p><strong>命令行接口</strong></p>

<ul>
<li>hadoop fs -help</li>
<li>hadoop fs -copyFromLocal input/docs/qu.txt hdfs://localhost/user/tom/qu.txt</li>
<li>md5 input/docs/qu.txt qu.copy.txt</li>
<li>hadoop fs -mkdir books</li>
<li>hadoop fs ls</li>
</ul>


<p>接口</p>

<ul>
<li>Thrift</li>
<li>libhdfs</li>
<li>fuse</li>
<li>webdav</li>
<li>http</li>
<li>ftp</li>
</ul>


<p><strong>Java接口</strong></p>

<h3>数据流</h3>

<h2>hadoop的I/O</h2>

<h3>序列化</h3>

<p>writable是MapReduce数据路径的核心。</p>

<p><strong>序列化框架</strong></p>

<h3>基于文件的数据结构</h3>

<p><strong>SequenceFile</strong></p>

<p>key/value结构</p>

<p><strong>MapFile</strong></p>

<p>sorted SequenceFile</p>

<h2>MapReduce开发</h2>

<p>大致流程</p>

<ul>
<li>编写map, reduce函数</li>
<li>单元测试</li>
<li>运行驱动作业</li>
<li>集群运行</li>
<li>调试错误</li>
<li>调整性能</li>
</ul>


<h3>配置环境</h3>

<h3>单元测试</h3>

<h3>本地运行</h3>

<h3>集群运行</h3>

<p>不需要修改，直接打包后运行</p>

<p>拥有网络观察界面</p>

<p>调试方法，日志解析方法</p>

<p>调优列表</p>

<ul>
<li>mapper数量</li>
<li>reducer数量</li>
<li>是否利用combainer</li>
<li>中间值</li>
<li>自定义序列</li>
<li>shuffle运行</li>
</ul>


<h3>MapReduce工作流</h3>

<p>高级语言</p>

<ul>
<li>Pig</li>
<li>HIHV</li>
<li>Cascading</li>
</ul>


<h2>MapReduce工作原理</h2>

<h3>运行作业</h3>

<ul>
<li>提交作业</li>
<li>作业初始化</li>
<li>任务分配</li>
<li>任务执行</li>
<li>进度状态更新</li>
<li>作业完成</li>
</ul>


<h3>失败的处理</h3>

<h3>作业调度</h3>

<p>早期FIFO使用整个</p>

<p>后来优先级队列</p>

<p>Fair Scheduler</p>

<h3>shuffle和排序</h3>

<p>shuffle&#8211; 系统排序的过程</p>

<p>优化的关键</p>

<p>很多时候是MapReduce的核心</p>

<h3>任务的执行</h3>

<h2>MapReduce类型和格式</h2>

<p>key/value输入输出</p>

<p>java本身问题导致的类型摩擦</p>

<h3>输入格式</h3>

<p>大量小文件会降低MapReduce性能，因为会增加seek操作，而且每次新map会造成性能损失，MapReduce最佳处理速度最好与数据在集群中传播速度
相同。所以将大量的小文件打包成一个整块的文件</p>

<p>hadoop擅长处理结构化的数据</p>

<p>文本和文件格式的输入</p>

<p>数据库输入</p>

<h3>输出格式</h3>

<p>一个分区对应一个固定的分区不好，导致分区不均。</p>

<p>让很多reducer去做较轻的工作也不佳，更好的是用少量的reducer,每个做更多的活，这样便于管理reducer.</p>

<h2>MapReduce特性</h2>

<ul>
<li>计数器</li>
<li>排序</li>
<li>数据集链接</li>
</ul>


<p>对数据排序是MapReduce的核心。</p>

<h2>HBase</h2>

<p>分布式的面向列的存储系统。对于实时写和随机访问大的数据有效。</p>

<p>公认的用例是webtable。</p>

<h3>背景</h3>

<p>最初由Powerset的chad walter等从2006年开发，基于google的论文&#8221;Bigtable; A distributed Storage System for structured Data&#8221;.
最初是haddop的一部分，2008年成为apache的一个子项目。</p>

<h3>概念</h3>

<p><strong>数据模型</strong></p>

<p>表的行作为主键，被排序</p>

<p>列被分为列族</p>

<p>所有列族成员被存储在一起</p>

<p><strong>区域</strong></p>

<p>自动横向切分区域</p>

<p>区域是分散在hbase内的单元</p>

<p><strong>锁定</strong></p>

<p>行的更新是原子的</p>

<p><strong>实现</strong></p>

<p>一个主节点和多个区域服务器</p>

<p>依赖于zookeeper</p>

<p><strong>运行</strong></p>

<p>-ROOT-和.MEAT.目录表</p>

<p>客户端缓存已知的-ROOT-和.MEAT.</p>

<h3>安装</h3>

<p>解压</p>

<p>设置路径</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$export</span> <span class="nv">HBASE_HOME</span><span class="o">=</span>/home/hbase
</span><span class='line'><span class="nv">$export</span> <span class="nv">PATH</span><span class="o">=</span><span class="nv">$PATH</span>:<span class="nv">$HBASE_HOME</span>/bin
</span></code></pre></td></tr></table></div></figure>


<p>运行</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$hbase</span>
</span></code></pre></td></tr></table></div></figure>


<p>测试驱动</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$start</span>-hbase.sh
</span></code></pre></td></tr></table></div></figure>


<h3>客户端</h3>

<p><strong>java</strong></p>

<p><strong>REST thrift</strong></p>

<h3>同RDBMS比较</h3>

<ul>
<li>HBase：分布式，面向列，hdfs上读写，自动横向分区和复制。</li>
<li>RDBMS：满足ACID的，面向行的，通过SQL查询，</li>
</ul>


<p>HBase特点</p>

<ul>
<li>无真正索引</li>
<li>自动分区</li>
<li>创建新节点时自动线性扩展</li>
<li>商用硬件</li>
<li>容错性</li>
<li>批处理性</li>
</ul>


<h3>实践</h3>

<p><strong>缺点</strong></p>

<ul>
<li>文件描述信息块耗尽&#8221;Too many open files&#8221;</li>
<li>数据节点线程用尽</li>
<li>不良块</li>
</ul>


<p><strong>用户界面</strong></p>

<p>web界面，默认60010端口</p>

<p><strong>度量</strong></p>

<p><strong>架构</strong></p>

<p>类似RDMBS，但是单元有版本，行排序</p>

<h3>参考</h3>

<p><a href="http://www.searchtb.com/2011/01/understanding-hbase.html">HBase技术介绍</a></p>

<h2>Zookeeper简介</h2>

<p>分布式协调管理</p>

<p>特性</p>

<ul>
<li>简易</li>
<li>易表达</li>
<li>高可用</li>
<li>简化松耦合</li>
<li>开源库</li>
</ul>


<h3>安装运行</h3>

<p>解压</p>

<p>设置路径</p>

<p>单机版测试</p>

<p>联机版测试</p>

<h3>范例说明</h3>

<p><strong>znode</strong></p>

<p><strong>watcher</strong></p>

<h3>服务</h3>

<p><strong>数据模型</strong></p>

<ul>
<li>znode  ACL</li>
<li>临时znode</li>
<li>序号：全局唯一</li>
<li>watch</li>
<li>API绑定</li>
</ul>


<p><strong>操作</strong></p>

<ul>
<li>create</li>
<li>delete</li>
<li>exists</li>
<li>getACL, setACL</li>
<li>getChildren</li>
<li>getData, setData</li>
<li>sync</li>
</ul>


<p><strong>watch触发</strong></p>

<p><strong>ACL</strong></p>

<p><strong>运行</strong></p>

<p>集群内多数可用即可，5台容忍坏2台，6台允许坏2台，所以一般选择奇数个机器组成
集群</p>

<p>采用了zab协议</p>

<ul>
<li>领导者选举 200ms</li>
<li>原子广播</li>
</ul>


<p><strong>一致性</strong></p>

<ul>
<li>zxid</li>
<li>顺序一致性</li>
<li>原子性</li>
<li>单系统映像</li>
<li>容错性</li>
<li>合时性</li>
</ul>


<p>内存提供读写操作</p>

<p>sync只能被异步调用</p>

<p><strong>会话</strong></p>

<p>和临时znode相关</p>

<p><strong>time参数</strong></p>

<ul>
<li>tick time: 基本时长</li>
</ul>


<p><strong>状态</strong></p>

<h3>使用</h3>

<p><strong>配置服务</strong></p>

<p>读写，监视</p>

<p><strong>可恢复的应用</strong></p>

<ul>
<li>InterruptedException</li>
<li>KeeperException</li>
</ul>


<p><strong>锁服务</strong></p>

<ol>
<li>znode下创建， znode-child-x</li>
<li>获取znode的children并设置watch</li>
<li>如果步骤1中的路径名和步骤2中的路径名的最小值相同，得到锁，否则等待或退出</li>
<li>一旦znodechildren改变则被watch到，继续步骤3的比较</li>
</ol>


<p>集群影响问题</p>

<p>解决：提高发送消息的条件，不是每次都发送。</p>

<p>可恢复的异常</p>

<p>创建锁的客户端异常，没有释放。则死锁。</p>

<p>解决：在znode名称中嵌入标识符。</p>

<p>不可恢复的异常</p>

<p>WriteLock</p>

<p><strong>其他分布式协议</strong></p>

<p><strong>BookKeeper</strong></p>

<p>日志模块</p>

<h3>工业中的Zookeeper</h3>

<ul>
<li>集群限制在单一的数据中心</li>
<li>Zookeeper单独运行在服务器上，不合其他服务竞争资源</li>
<li>配置Zookeeper保存不同磁盘上的快照驱动的日志。</li>
<li>进程与磁盘进行交换。性能受影响。通过设置java堆大小和减少物理机器内存避免。</li>
</ul>


<h2>参考</h2>

<p><a href="http://blog.sina.com.cn/s/blog_61ef49250100uvab.html">Ubuntu上搭建Hadoop环境</a></p>
</div>


  <footer>
    <p class="meta">
      
  

<span class="byline author vcard">Posted by <span class="fn">windfire.cd</span></span>

      








  


<time datetime="2012-07-05T18:14:00+08:00" pubdate data-updated="true">Jul 5<span>th</span>, 2012</time>
      


    </p>
    
      <div class="sharing">
  
  <a href="http://twitter.com/share" class="twitter-share-button" data-url="http://windfire-cd.github.com/blog/2012/07/05/hadoop/" data-via="" data-counturl="http://windfire-cd.github.com/blog/2012/07/05/hadoop/" >Tweet</a>
  
  
  
</div>

    
    <p class="meta">
      
        <a class="basic-alignment left" href="/blog/2012/07/04/buildbot-test-framework/" title="Previous Post: BuildBot Test Framework">&laquo; BuildBot Test Framework</a>
      
      
        <a class="basic-alignment right" href="/blog/2012/07/09/bitcask/" title="Next Post: bitcask">bitcask &raquo;</a>
      
    </p>
  </footer>
</article>

  <section>
    <h1>Comments</h1>
    <div id="disqus_thread" aria-live="polite"><noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
  </section>

</div>

<aside class="sidebar">
  
    <section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2012/12/25/ubuntu-sudo-wu-mi-ma/">Ubuntu sudo 无密码</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/12/24/keepalivedshi-yong/">Keepalived使用</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/12/18/openstack-install-on-ubuntu/">OpenStack Install On Ubuntu</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/12/10/install-hadoop-on-ubuntu/">Install Hadoop on Ubuntu</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/11/15/c10k-xiang-guan/">C10k 相关</a>
      </li>
    
  </ul>
</section>






  
</aside>


    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2012 - windfire.cd -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'windfire-cd-comments';
      
        
        // var disqus_developer = 1;
        var disqus_identifier = 'http://windfire-cd.github.com/blog/2012/07/05/hadoop/';
        var disqus_url = 'http://windfire-cd.github.com/blog/2012/07/05/hadoop/';
        var disqus_script = 'embed.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>







  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'http://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>


<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>My Octopress Blog</title>
  <meta name="author" content="windfire.cd">

  
  <meta name="description" content="简介 Zookeeper是一个开源的分布式的协调服务框架，主要为分布式应用程序提供服务。它提供一些列简单的原语进行同步，配置维护，全局命名
等服务。它是java语言实现的，但是可以绑定运行java以及c的程序 它的主要作用是提供协调服务，减轻分布式应用程序的协调负担。 目标 简单 &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://windfire-cd.github.com/blog/page/2/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="/javascripts/ender.js"></script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <link href="/atom.xml" rel="alternate" title="My Octopress Blog" type="application/atom+xml">
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  

</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">My Octopress Blog</a></h1>
  
    <h2>life and I</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:windfire-cd.github.com" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2012/08/15/zookeeper-intro/">Zookeeper Intro</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2012-08-15T10:48:00+08:00" pubdate data-updated="true">Aug 15<span>th</span>, 2012</time>
        
         | <a href="/blog/2012/08/15/zookeeper-intro/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h2>简介</h2>

<p><a href="http://zookeeper.apache.org/">Zookeeper</a>是一个开源的分布式的协调服务框架，主要为分布式应用程序提供服务。它提供一些列简单的原语进行同步，配置维护，全局命名
等服务。它是java语言实现的，但是可以绑定运行java以及c的程序</p>

<p>它的主要作用是提供协调服务，减轻分布式应用程序的协调负担。</p>

<h2>目标</h2>

<h3>简单</h3>

<p>对于zookeeper来说，每个分布式节点类似于一个文件系统的文件。它为其提供分层命名空间下的协调通信服务。zookeeper将数据保存在内存中
而不是硬盘中，所以时延较低</p>

<h3>分布式</h3>

<p>zookeeper本身就是分布式的</p>

<p><img src="http://zookeeper.apache.org/doc/trunk/images/zkservice.jpg"></p>

<p>运行在不同机器上的zookeeper服务可以彼此通信。如果大部分的服务器运转正常，则zookeeper依然可用。</p>

<blockquote><p>即少部分的机器异常不影响整体服务
每个client都和一个server保持tcp链接
client通过这个链接传递请求和响应以及心跳，一旦server异常，client可以立刻链接别的server</p></blockquote>

<h3>有序</h3>

<p>zookeeper对每次更新提供一个全局序数，随后的操作可以利用该序数进行高层一致性抽象操作，比如同步</p>

<blockquote><p>zookeeper提供全局锁，类似google  chuddy？</p></blockquote>

<h3>快速</h3>

<p>zookeeper是一个读取操作比写入操作要快的服务，在上千个服务器上运行zookeeper的话，一般来说，读写速度是10：1</p>

<blockquote><p>考虑到分布式的特性，读可以进行分离，但是写的话需要锁以及一致性操作</p></blockquote>

<h2>架构</h2>

<p><img src="http://zookeeper.apache.org/doc/trunk/images/zknamespace.jpg"></p>

<p>zookeeper的提供一个分层的命名空间。每个节点都可以有孩子节点，类似于文件系统中每个文件也可以作为文件夹。节点被称为znode</p>

<p>znode保存一个包含数据修改版本，ACL修改记录，以及时间戳的状态结构。允许缓存验证和协调更新。每次状态结构修改，则版本自增1.</p>

<p>znode上的数据读取和写入提供原子操作。zookeeper可以允许存在临时节点，节点生存周期和session相同。</p>

<p>zookeeper提供观察功能，client可以作为znode的观察者，一旦znode数据发生变换，那么client会被通知。</p>

<h2>一致性</h2>

<ul>
<li>顺序一致性：client的更新会被按照发送顺序操作</li>
<li>原子性：更新或者成功或者失败，不会出现其他结果</li>
<li>单一的系统链接表示：所有client观察到的系统都是</li>
<li>可靠性：一旦更新提交了，在下一个更新来之前都是有效的</li>
<li>时效性：对于client来说，看到的都是最新的数据</li>
</ul>


<h2>API</h2>

<ul>
<li>create</li>
<li>delete</li>
<li>exists</li>
<li>get data</li>
<li>set data</li>
<li>get chirldren</li>
<li>sync</li>
</ul>


<h2>实现</h2>

<p>下面是zookeeper的结构图</p>

<p><img src="http://zookeeper.apache.org/doc/trunk/images/zkcomponents.jpg"></p>

<p>在zookeeper服务中，每个zookeeper的节点都有上述几个模块</p>

<p>replicated database是一个内存数据库，保存修改日志到硬盘上。</p>

<p>每个client端，连接一个指定的server提交相关的request。可以从当前server中读取相关信息。</p>

<p>作为协议公认的方式，所有的信息写入都发给一个当前系统固定的server，被称为leader.其他的server被称为follower.其中follower从leader获取
相关消息。zookeeper的消息层负责leader失效的重新选举和follower同步。</p>

<h2>使用及性能</h2>

<p>使用zookeeper提供的高层api，可以完成分布式系统中的同步原语，分组以及所有权管理。
其性能测试如下</p>

<p><img src="http://zookeeper.apache.org/doc/trunk/images/zkperfRW-3.2.jpg"></p>

<p><a href="http://zookeeper.apache.org/doc/trunk/zookeeperOver.html">Overview</a></p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2012/08/13/twitter-storm/">Twitter Storm</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2012-08-13T10:20:00+08:00" pubdate data-updated="true">Aug 13<span>th</span>, 2012</time>
        
         | <a href="/blog/2012/08/13/twitter-storm/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h2>简介</h2>

<p>Twitter Storm是Twitter开源的一个实时流数据处理框架，主要基于Java，部分可用
python。原来是BackType开发的，后被Twitter收购，整理后开源。主要用于下面三个领域</p>

<ol>
<li>信息流处理(stream processing): 处理实时数据和更新数据库</li>
<li>连续计算(continuous computation): 可以连续查询并反馈给用户</li>
<li>分布式远程过程调用(distributed rpc): 处理密集数据。</li>
</ol>


<p>特点如下</p>

<ol>
<li>编程模型类似mapreduce，简化复杂性</li>
<li>使用各种语言，默认支持clojure, java, ruby, python。支持其他语言需要实现storm的通信协议</li>
<li>容错性。管理工作进程和节点的故障</li>
<li>水平扩展。计算在多线程，进程和服务器间进行</li>
<li>可靠消息处理。storm保证每个消息至少被完整处理一次</li>
<li>快速。 使用zeromq为底层消息队列</li>
<li>本地模式。用于快速开发和调试</li>
</ol>


<h2>storm-start</h2>

<h3>编译及安装</h3>

<p><strong>jdk</strong></p>

<p>首先需要安装jdk支持否则会提示缺少<em>tools.jar</em>，需要注意的是要安装jdk6，jdk7编译
会有问题。具体步骤见<a href="http://www.devsniper.com/ubuntu-12-04-install-sun-jdk-6-7/">install jdk on ubuntu</a></p>

<p><em>注意如果先安装jdk，然后安装maven2的话，需要重新设置下jdk版本，具体见上面的安装</em></p>

<p><strong>twitter4j</strong></p>

<p>然后去下载<a href="https://github.com/twitter/twitter4j.git">twitter4j</a>，否则安装时会
提示缺少这个库支持，而且也下载不来，应该是被墙了。</p>

<p>在编译twitter4j时，利用其文件夹内的package.sh文件。只有twitter-core编译成功
其他的没有库支持，而且也下不来，需要首先安装twitter-core</p>

<p>下载最新的jdk6进行编译的话，缺少json包支持，需要在twitter4j-core文件夹中的
pom.xml中添加json包依赖见<a href="http://mvnrepository.com/artifact/org.json/json/20090211">maven2 json</a></p>

<p>需要忽略test进行编译打包，首先完成core的编译，然后安装</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$cd</span>  twitter4j-core
</span><span class='line'><span class="nv">$mvn</span> compile
</span><span class='line'><span class="nv">$mvn</span> package -Dmaven.test.skip<span class="o">=</span><span class="nb">true</span>
</span><span class='line'><span class="nv">$mvn</span> install:install-file -DgroupId<span class="o">=</span>org.twitter4j -DartifactId<span class="o">=</span>twitter4j-core -Dversion<span class="o">=</span>2.2.6-SNAPSHOT -Dpackaging<span class="o">=</span>jar -Dfile<span class="o">=</span>target/twitter4j-core-2.2.6-SNAPSHOT.jar
</span><span class='line'><span class="nv">$cd</span> ..
</span></code></pre></td></tr></table></div></figure>


<p>然后编译安装twitter-async</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$cd</span> twitter4j-async
</span><span class='line'><span class="nv">$mvn</span> compile
</span><span class='line'><span class="nv">$mvn</span> package -Dmaven.test.skip<span class="o">=</span><span class="nb">true</span>
</span><span class='line'><span class="nv">$mvn</span> install:install-file -DgroupId<span class="o">=</span>org.twitter4j -DartifactId<span class="o">=</span>twitter4j-async -Dversion<span class="o">=</span>2.2.6-SNAPSHOT -Dpackaging<span class="o">=</span>jar -Dfile<span class="o">=</span>target/twitter4j-async-2.2.6-SNAPSHOT.jar
</span><span class='line'><span class="nv">$cd</span> ..
</span></code></pre></td></tr></table></div></figure>


<p>最后编译安装twitter-stream</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$cd</span> twitter4j-stream
</span><span class='line'><span class="nv">$mvn</span> compile
</span><span class='line'><span class="nv">$mvn</span> package -Dmaven.test.skip<span class="o">=</span><span class="nb">true</span>
</span><span class='line'><span class="nv">$mvn</span> install:install-file -DgroupId<span class="o">=</span>org.twitter4j -DartifactId<span class="o">=</span>twitter4j-stream -Dversion<span class="o">=</span>2.2.6-SNAPSHOT -Dpackaging<span class="o">=</span>jar -Dfile<span class="o">=</span>target/twitter4j-stream-2.2.6-SNAPSHOT.jar
</span><span class='line'><span class="nv">$cd</span> ..
</span></code></pre></td></tr></table></div></figure>


<p><strong>storm-start</strong></p>

<p>利用maven进行编译测试</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>mvn -f m2-pom.xml compile <span class="nb">exec</span>:java -Dexec.classpathScope<span class="o">=</span>compile -Dexec.mainClass<span class="o">=</span>storm.starter.WordCountTopology
</span></code></pre></td></tr></table></div></figure>


<p>打包</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>mvn -f m2-pom.xml package
</span></code></pre></td></tr></table></div></figure>


<p>注：如果需要在单机模式下运行打包内的文件，需要首先安装storm的release版本
然后运行</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>storm jar target/storm-starter-0.0.1-SNAPSHOT-jar-with-dependencies.jar storm.starter.WordCountTopology
</span></code></pre></td></tr></table></div></figure>


<h2>安装storm</h2>

<h3>依赖</h3>

<p><strong>build-essential</strong></p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>sudo apt-get install build-essential
</span></code></pre></td></tr></table></div></figure>


<p><strong>zookeeper</strong></p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'> wget http://ftp.meisei-u.ac.jp/mirror/apache/dist//zookeeper/zookeeper-3.3.3/zookeeper-3.3.3.tar.gz
</span><span class='line'> tar zxf zookeeper-3.3.3.tar.gz
</span><span class='line'> cp -R zookeeper-3.3.3 /usr/local/
</span><span class='line'> ln -s /usr/local/zookeeper-3.3.3/ /usr/local/zookeeper
</span><span class='line'> vi ~./bashrc <span class="o">(</span>设置ZOOKEEPER_HOME和ZOOKEEPER_HOME/bin<span class="o">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>编辑/etc/enviroment,添加</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">ZOOKEEPER_HOME</span><span class="o">=</span>/usr/loacl/zookeeper
</span><span class='line'><span class="nv">PATH</span><span class="o">=</span><span class="s2">&quot;$PATH:$ZOOKEEPER_HOME/bin&quot;</span>
</span></code></pre></td></tr></table></div></figure>


<p>设置配置文件</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'> cp /usr/local/zookeeper/conf/zoo_sample.cfg /usr/local/zookeeper/conf/zoo.cfg <span class="o">(</span>用zoo_sample.cfg制作<span class="nv">$ZOOKEEPER_HOME</span>/conf/zoo.cfg<span class="o">)</span>
</span><span class='line'> sudo mkdir /tmp/zookeeper
</span><span class='line'> sudo mkdir /var/log/zookeeper
</span></code></pre></td></tr></table></div></figure>


<p>好的，zookeeper的单机安装已经完成了。</p>

<p><strong>zeromq</strong></p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'> wget http://download.zeromq.org/historic/zeromq-2.1.7.tar.gz
</span><span class='line'> tar zxf zeromq-2.1.7.tar.gz
</span><span class='line'> <span class="nb">cd </span>zeromq-2.1.7
</span><span class='line'> ./configure
</span><span class='line'> make
</span><span class='line'> make install
</span><span class='line'> sudo ldconfig <span class="o">(</span>更新LD_LIBRARY_PATH<span class="o">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>./configure时会遇到uuid</p>

<p><strong>jzmq</strong></p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'> <span class="nb">cd </span>jzmq
</span><span class='line'> ./autogen.sh
</span><span class='line'> ./configure
</span><span class='line'> touch src/classdist_noinst.stamp
</span><span class='line'> <span class="nb">cd </span>src/org/zeromq/
</span><span class='line'> javac *.java
</span><span class='line'> <span class="nb">cd</span> ../../../
</span><span class='line'> make
</span><span class='line'> sudo make install
</span></code></pre></td></tr></table></div></figure>


<p>需要安装pkg-config, libtool, automake</p>

<p>需要创建<em>classdist_noinst.stamp</em>后编译java文件否则会报错</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="sb">`</span>classdist_noinst.stamp<span class="s1">&#39;, needed by `org/zeromq/ZMQ.class&#39;</span>.  Stop
</span></code></pre></td></tr></table></div></figure>


<p>完成后设置PATH</p>

<h2>参考</h2>

<p><a href="http://hitina.lofter.com/post/a8c5e_12e927/">Twitter Storm：What &amp; Why？</a></p>

<p><a href="http://www.open-open.com/lib/view/open1328286398374.html">Twitter Storm 实时数据处理框架分析总结</a></p>

<p><a href="http://chenlx.blog.51cto.com/4096635/748737">Twitter Storm 在生产集群运行拓扑</a></p>

<p><a href="http://blog.csdn.net/azhao_dn/article/category/937267">Twitter Storm blog 参考</a></p>

<p><a href="http://blog.csdn.net/larrylgq/article/details/7326058">blog one</a></p>

<p><a href="http://blog.csdn.net/larrylgq/article/details/7326058">tter storm 配置项 </a></p>

<p><a href="https://github.com/nathanmarz/storm-starter">storm-starter</a></p>

<p><a href="https://github.com/nathanmarz/storm/">storm</a></p>

<p><a href="http://hitina.lofter.com/post/a8c5e_136579/">Twitter Storm 安装实战</a></p>

<p><a href="http://my.oschina.net/mingdongcheng/blog/43009">安装twitter storm集群组件ZeroMQ，jzmq时遇到的一系列问题</a></p>

<p><a href="http://www.cnblogs.com/panfeng412/">taobaoer blog</a></p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2012/08/09/apache-kafka-jie-shao/">Apache Kafka 介绍</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2012-08-09T18:20:00+08:00" pubdate data-updated="true">Aug 9<span>th</span>, 2012</time>
        
         | <a href="/blog/2012/08/09/apache-kafka-jie-shao/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h2>来源</h2>

<p>此项目最开始由Linkedln开发并开源的一个消息系统。Linkdeln将其作为
可读写的流以及服务状态的数据管道。对于一个网站来说，读写流
经常用来记录页面浏览信息，展示信息以及搜素信息，这些信息一般由日志
系统进行记录。服务状态包括当前机器的cpu, IO, 请求时间， 服务日志等。
近年来，服务状态日益成为衡量网站质量的标志。</p>

<h2>使用读写流以及服务状态的例子</h2>

<ul>
<li>消息广播(News feed) 朋友活动的广播</li>
<li>用户评分以及相关性计算</li>
<li>安全：需要可以进行监测恶意攻击，平衡集群负载等操作</li>
<li>监控</li>
<li>报表以及离线数据处理：hadoop</li>
</ul>


<h2>活跃数据特性</h2>

<p>大流量的数据活跃无法确定大小。传统的日志方式是一种离线的处理方式
比如离线的报告和压缩。对于实时系统，这种方式时延就泰高了。现有的消息队列系统
处理周期。kafka作为一个队列系统可以分别处理离线以及实时的问题。</p>

<h2>linkdedln的模块结构</h2>

<p><img src="http://incubator.apache.org/kafka/images/tracking_high_level.png"></p>

<p>一个kafka的队列系统可以对应于多个模块的数据处理。还可以利用其进行不同数据中心的
数据备份。</p>

<p>kafka集群并不是在数据中心中集中进行部署并提供服务，而是根据数据流拓扑部署多个
集群，不同集群间通过同步来进行数据流处理，其中镜像集群只是源集群的一个消费者。
下面的图示表示了这个过程</p>

<p><img src="http://incubator.apache.org/kafka/images/kafka_multidc.png"></p>

<h2>kafka设计</h2>

<ul>
<li>kafka为一般情况下的持久化消息队列系统</li>
<li>设计约束主要考量吞吐量而不是功能</li>
<li>消息处理模块记录所处理消息的状态，而不是消息提供模块</li>
<li>kafka被设计为分布式部署，其中消息的生产者，代理者和消费者可以分布于整个集群</li>
</ul>


<h3>基础</h3>

<p>消息是模块间通信的基础单元，消息被发布到代理不同主题的服务器上，某些消费模块
订阅该主题，那么所有被发布的消息都被订阅该主题的消费者收到。</p>

<p>kafka的分布式方案对于生产者和代理者来说比较明晰，但是对于消费者，需要一个特别的
设置和支持。消费者组的概念可以类似于JMS中的队列以及主题，这里的消费者组
可以作为一个逻辑上的单一消费者出现在集群中。对于队列，可以把所有的消费者
作为一个组，而将不同的消费者组成不同的组则对应了主题。一般的情况是根据
不同的主题分为不同的逻辑组，逻辑组作为一个单独的对象出现在集群中。kafka的一个
额外特性是在大量的数据下，不论一个主题内有多少消费者，一个消息只存储一次。</p>

<h3>消息持久化和缓存</h3>

<p>Kafka的持久化和缓存依赖于文件系统。对于硬盘来说，顺序读写的性能是随机读写性能
的10000倍，某些情况下顺序访问硬盘比随机访问内存要快。</p>

<p>现代操作系统都会为硬盘申请内存作为缓存。操作系统会倾向于将所有空闲的内存
分配给硬盘作为缓存，虽然这样会造成内存重新申请的性能损失。硬盘通过该缓冲区进行
读写，这个特性除非用直接的I/O操作，否则不会轻易被关闭。所以，即使一个进程缓存了
所有的数据，该数据也可能被复制进系统页缓存中，这样造成所有的东西被存储了2次</p>

<p>另外，基于JVM的应用对于内存的使用存在两个问题</p>

<ol>
<li>对象使用内存很高基本两倍于对象存储的内存</li>
<li>在堆内数据增长的时候，垃圾回收机制比较简单和消耗性能</li>
</ol>


<p>由于上面两点，利用文件系统缓存机制要优于直接利用内存缓存或类似机制。因此
kafka至少保持可用内存的两倍大小的缓存，如果需要存储压缩数据，则变成4倍大小
因此，对于一个32GB内存的机器，kafka会保持28-30GB的缓存，而不需要担心GC影响。
另外，一旦服务重启，这个缓存可以快速的重新载入，而进程内缓存需要在内存中重新申请
或者由代码进行初始化。所以这种机制简化了代码逻辑，对于内存和文件系统的同步
由操作系统完成。</p>

<p>基于以上，这种设计非常简单：不是在内存中保存数据，然后需要的时候flush进硬盘
，而是反过来，首先将所有数据写入文件系统的一个持久化日志中而不是由进程调用
flush数据操作。这意味着只要将数据写入内核页缓存中，然后给系统一个配置，多长
时间或者多大数据后将数据flush进硬盘中即可。</p>

<h3>恒定的时间消耗</h3>

<p>一般来说消息系统的元数据都是BTree存储的，虽然其可操作性强，时间开销是O(logN).
但是结合硬盘操作后，随机查找增多造成性能损耗严重。而日志系统的读取是顺序，
写入是直接在文件后进行添加，虽然比BTree没有更好的操作性，但是时间开销是O(1)
的，而且读取不会锁住写入操作或者彼此加锁。这样设计的一个显著优势是不再受数据大小的限制。
这样可以保存数据很长的时间，而不是一旦消息被分发就会被删除。</p>

<h3>效率优化手段</h3>

<p>假设消息量较大，但是对于每个发布的消息而言，消费的次数要大于生成的次数，因此
优化的手段在消费者更加有效。</p>

<p>两个影响性能的部分为</p>

<ul>
<li>大量的网络请求</li>
<li>多余的数据拷贝</li>
</ul>


<p>对于网络请求，根据消息特性进行分组，可以将同组消息打包为&#8221;message set&#8221;，每次
可以将多个消息打包后发送，而不是单独发送每个消息。对于MessageSet，接口简单
一般不需要进行序列化和反序列化</p>

<p>消息日志被broker保存其硬盘上。因此，即使单个字节的消息也可以被不同的brokeer和
consumer共享。</p>

<p>现代unix系统可以支持代码直接将页面缓存的数据直接发送给网络缓存，减少中间拷贝
次数。Linux中利用sendfile系统调用完成这个功能，Java提供了标准库调用FileChannel.transferTo
接口</p>

<p>一般来说对于通过socket发送系统中的数据需要通过以下几个步骤</p>

<ol>
<li>内核空间上，硬盘读取到页面缓存</li>
<li>用户空间读取内核空间的数据</li>
<li>在将数据从用户空间写入到内核空间的socket缓存</li>
<li>系统将socket缓存中的数据拷贝到NIC缓存中</li>
</ol>


<p>需要4此拷贝，2次系统调用。利用sendfile，可以直接将页面缓存拷贝到网络中，
因此只有第4步拷贝到NIC缓存中</p>

<p>对于同个主题的多个consumer，利用zero-copy技术，数据只需要拷贝到页面缓存中
一次，并且对于多个网络输出进行复用，因此速度基本可达网络硬件的上限。</p>

<h3>端到端的压缩</h3>

<p>某些时候，系统瓶颈不再于cpu而是网络能力。而由用户简单的将消息压缩后传送给
消息系统无法降低消息间的冗余，更有效的消息压缩应该是将一组消息进行压缩后传输，
更理想的是端到端的方式，数据传输前被压缩后通过producer传输给server，server
不解压直接传送给cosumer，然后由consumer进行解压。</p>

<p>kafka支持递归的消息集合。一组消息被打包后传输给server，然后这组消息被传输给
所有的consumer进行解压后处理。</p>

<h3>消费者状态</h3>

<h3>分布式</h3>

<h3>生产者</h3>

<h3>支持hadoop和其他数据载入</h3>

<h2>实现细节</h2>

<h3>API设计</h3>

<h3>网络层设计</h3>

<h3>消息设计及格式</h3>

<h3>日志</h3>

<h3>分布式</h3>

<h2>#</h2>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2012/08/09/slice-reading-0809/">Slice Reading 0809</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2012-08-09T14:23:00+08:00" pubdate data-updated="true">Aug 9<span>th</span>, 2012</time>
        
         | <a href="/blog/2012/08/09/slice-reading-0809/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h2>TimeTunel</h2>

<p>对现有日志的跟踪</p>

<ul>
<li>基于thrift</li>
<li>zookeeper做负载均衡以及分配</li>
<li>环状的broker的repulication</li>
</ul>


<h2>pytailer</h2>

<p><a href="https://github.com/six8/pytailer">pytailer</a></p>

<h2>Durable Event Data Transport at Scale</h2>

<p><a href="http://sharadag.tumblr.com/post/13549427326/durable-event-data-transport-at-scale">link</a></p>

<h2>Twitter Storm Transactional topologies</h2>

<p><a href="https://github.com/nathanmarz/storm/wiki/Transactional-topologies">Transactional topologies</a>
是关于Twitter Storm内部消息持久化的拓扑设计。</p>

<p><a href="http://xumingming.sinaapp.com/109/twitter-storm%E7%AE%80%E4%BB%8B/">chinese intro</a></p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2012/08/09/zikpin-intro/">Zikpin Intro</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2012-08-09T11:31:00+08:00" pubdate data-updated="true">Aug 9<span>th</span>, 2012</time>
        
         | <a href="/blog/2012/08/09/zikpin-intro/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h2>简介</h2>

<p>Zipkin是一个分布式的追踪系统，可以通过该系统获取各个服务的时间数据。Twitter用
它来管理信息收集以及查询服务组件。它的思想来源于<a href="http://research.google.com/pubs/pub36356.html">Google Dapper</a></p>

<p>对一个分布式系统进行跟踪监控的原因在于我们可以获取系统服务的深层次数据，比如
某个服务的响应时间，根据这点可以判断当前分布式系统的性能瓶颈以及其他信息。Zikpin
获取这些信息后通过浏览器显示在web上</p>

<p>其体系结构如下</p>

<p><img src="https://github.com/twitter/zipkin/raw/master/doc/architecture-0.png"></p>

<p>每个被追踪的消息在系统中传送时都带了一个追踪标识，zipkin通过该标识在追踪系统
中标记信息，判断时间。所有带有追踪标识的消息在被服务端传送出去时通过工具库将
该消息传送给zipkin系统。</p>

<p>{ % img https://github.com/twitter/zipkin/raw/master/doc/architecture-1.png % }</p>

<h2>组件</h2>

<p><strong>Finagle</strong></p>

<blockquote><p>这使一个基于JVM的异步网络框架，通过它可以创建异步RPC，任何基于JVM的语言都
可以用它来创建客户端/服务端</p></blockquote>

<p><em>Frinagle</em>在twitter中被广泛使用。可以在其上添加追踪功能，目前客户端和服务端均
支持Trift和HTTP协议，缓存部分只支持Memcache和Redis(So far we have client/server support for Thrift and HTTP as well as client only support for Memcache and Redis.)</p>

<p>初始化一个finagle server并绑定追踪服务</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="n">ServerBuilder</span><span class="o">()</span>
</span><span class='line'>  <span class="o">.</span><span class="na">codec</span><span class="o">(</span><span class="n">ThriftServerFramedCodec</span><span class="o">())</span>
</span><span class='line'>    <span class="o">.</span><span class="na">bindTo</span><span class="o">(</span><span class="n">serverAddr</span><span class="o">)</span>
</span><span class='line'>    <span class="o">.</span><span class="na">name</span><span class="o">(</span><span class="s">&quot;servicename&quot;</span><span class="o">)</span>
</span><span class='line'>      <span class="o">.</span><span class="na">tracerFactory</span><span class="o">(</span><span class="n">ZipkinTracer</span><span class="o">())</span>
</span><span class='line'>        <span class="o">.</span><span class="na">build</span><span class="o">(</span><span class="k">new</span> <span class="n">SomeService</span><span class="o">.</span><span class="na">FinagledService</span><span class="o">(</span><span class="n">queryService</span><span class="o">,</span> <span class="k">new</span> <span class="n">TBinaryProtocol</span><span class="o">.</span><span class="na">Factory</span><span class="o">()))</span>
</span></code></pre></td></tr></table></div></figure>


<p>初始化一个客户端类似上面的操作，一旦指定Zipkin为追踪服务，那么请求在开始和
结束的时候被自动追踪，相应的服务和机器也会被同时记录。</p>

<p>可以自定义添加更多的追踪信息</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="n">Trace</span><span class="o">.</span><span class="na">record</span><span class="o">(</span><span class="s">&quot;starting that extremely expensive computation&quot;</span><span class="o">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>除了字符串也可以添加key-value信息</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="n">Trace</span><span class="o">.</span><span class="na">recordBinary</span><span class="o">(</span><span class="s">&quot;http.response.code&quot;</span><span class="o">,</span> <span class="s">&quot;500&quot;</span><span class="o">)</span>
</span></code></pre></td></tr></table></div></figure>


<p><strong>Ruby Thrift</strong></p>

<p>利用一个gem追踪请求，可以用里面的RackHandler生成id，并通知追踪系统该id。下面
是一个ruby thrift client的例子</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'><span class="n">client</span> <span class="o">=</span> <span class="no">ThriftClient</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="no">SomeService</span><span class="o">::</span><span class="no">Client</span><span class="p">,</span> <span class="s2">&quot;127.0.0.1:1234&quot;</span><span class="p">)</span>
</span><span class='line'><span class="n">client_id</span> <span class="o">=</span> <span class="no">FinagleThrift</span><span class="o">::</span><span class="no">ClientId</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="ss">:name</span> <span class="o">=&gt;</span> <span class="s2">&quot;service_example.sample_environment&quot;</span><span class="p">)</span>
</span><span class='line'><span class="no">FinagleThrift</span><span class="o">.</span><span class="n">enable_tracing!</span><span class="p">(</span><span class="n">client</span><span class="p">,</span> <span class="n">client_id</span><span class="p">),</span> <span class="s2">&quot;service_name&quot;</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<p><strong>Querulous</strong></p>

<p>是一个一个SQL的接口库，基于Scala实现</p>

<p><strong>Cassie</strong></p>

<p>是一个Finagle内部的基于Cassandra client库的实现</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="n">cluster</span><span class="o">.</span><span class="na">keyspace</span><span class="o">(</span><span class="n">keyspace</span><span class="o">).</span><span class="na">tracerFactory</span><span class="o">(</span><span class="n">ZipkinTracer</span><span class="o">())</span>
</span></code></pre></td></tr></table></div></figure>


<p><strong>Transport</strong></p>

<p>利用Scribe作为传输模块，利用该模块可以将服务的追踪信息传输给zipkin和hadoop。</p>

<blockquote><p>Scribe已经停止开发了，是否有替换？</p></blockquote>

<p><strong>Zipkin collector daemon</strong></p>

<p>信息收集器，一旦追踪信息传送到收集器，该模块会判断其有效性，存储并索引它。</p>

<p><strong>Storage</strong></p>

<p>存储模块，现在是利用Cassandra实现。可以选择不同的存储方式</p>

<blockquote><p>比如HBase?</p></blockquote>

<p><strong>Zipkin query daemon</strong></p>

<p>查询模块，通过简单的Trift api查找追踪存储后的信息</p>

<p><strong>UI</strong></p>

<p>显示追踪信息，该模块是一个利用D3的Rails应用</p>

<p>模块间关系如下：</p>

<p><img src="https://github.com/twitter/zipkin/raw/master/doc/modules.png"></p>

<h2>安装配置</h2>

<h3>Cassandra</h3>

<pre><code>利用下面的命令链接当前工程
```bash
bin/cassandra-cli -host localhost -port 9160 -f zipkin-server/src/schema/cassandra-schema.txt
```
</code></pre>

<h3>Zookeeper</h3>

<h3>Scribe</h3>

<pre><code>Scribe配置如下

```xml
&lt;store&gt;
  category=zipkin
    type=network
      remote_host=123.123.123.123
        remote_port=9410
          use_conn_pool=yes
            default_max_msg_before_reconnect=50000
              allowable_delta_before_reconnect=12500
                must_succeed=no
                &lt;/store&gt;
```
</code></pre>

<h3>Zipkin server</h3>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>git clone https://github.com/twitter/zipkin.git
</span><span class='line'><span class="nb">cd </span>zipkin
</span><span class='line'>cp zipkin-scribe/config/collector-dev.scala zipkin-scribe/config/collector-prod.scala
</span><span class='line'>cp zipkin-server/config/query-dev.scala zipkin-server/config/query-prod.scala
</span><span class='line'>Modify the configs above as needed. Pay particular attention to ZooKeeper and Cassandra server entries.
</span><span class='line'>bin/sbt update package-dist <span class="o">(</span>This downloads SBT 0.11.2 <span class="k">if </span>it doesn<span class="err">&#39;</span>t already exist<span class="o">)</span>
</span><span class='line'>scp dist/zipkin*.zip <span class="o">[</span>server<span class="o">]</span>
</span><span class='line'>ssh <span class="o">[</span>server<span class="o">]</span>
</span><span class='line'>unzip zipkin*.zip
</span><span class='line'>mkdir -p /var/log/zipkin
</span><span class='line'>zipkin-scribe/scripts/collector.sh -f zipkin-scribe/config/collector-prod.scala
</span><span class='line'>zipkin-server/scripts/query.sh -f zipkin-server/config/query-prod.scala
</span></code></pre></td></tr></table></div></figure>


<h3>Zipkin UI</h3>

<p>是一个标准的Rails 3应用</p>

<ol>
<li>升级Zookeeper server的配置。用来定位查询器</li>
<li>发布到何时的Rail 3 server上</li>
</ol>


<p><strong>zipkin-tracer gem</strong></p>

<p>通过Rack Handler在Rails 应用中添加追踪信息，在 config.ru中</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'><span class="n">use</span> <span class="no">ZipkinTracer</span><span class="o">::</span><span class="no">RackHandler</span>
</span><span class='line'>  <span class="n">run</span> <span class="o">&lt;</span><span class="no">YOUR_APPLICATION</span><span class="o">&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<h2>运行一个简单的Hadoop任务</h2>

<p>如果设置Scribe存储到Hadoop上，会产生一系列难以操作数据的报告。因此，利用一个
<a href="http://github.com/twitter/scalding">Scalding</a>来写Hadoop任务</p>

<ol>
<li><p>要运行hadooop任务，需要生成一个全包含的jar包</p>

<p> <code>
 sbt 'project zipkin-hadoop' compile assemble
</code></p></li>
<li><p>修改scald.rb指向需要运行hadoop任务的机器名</p></li>
<li><p>如果需要，升级scald.rb中的jarfile的版本</p></li>
<li><p>通过scald.rb脚本运行hadoop任务</p>

<p> <code>bash
 ./scald.rb --hdfs com.twitter.zipkin.hadoop.[classname] --date yyyy-mm-ddThh:mm yyyy-mm-ddThh:mm --output [dir]
</code></p></li>
</ol>


<h2>Google论文笔记</h2>

<p><a href="http://research.google.com/pubs/pub36356.html">Google Dapper</a>是google发表于2010年的一篇关于分布式服务监控以及查询的论文</p>

<h3>目的</h3>

<h3>方式</h3>

<h3>跟随者</h3>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2012/08/09/interview-100-pro/">Interview 100 Pro</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2012-08-09T11:00:00+08:00" pubdate data-updated="true">Aug 9<span>th</span>, 2012</time>
        
         | <a href="/blog/2012/08/09/interview-100-pro/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h2>简述</h2>

<p>下面是关于程序员面试100题的相关笔记。不全面但是自己可以供参考</p>

<h2>题目</h2>

<h3>题目1</h3>

<p><em>输入一棵二元查找树,将该二元查找树转换成一个排序的双向链表。要求不能创建任何
新的结点,只调整指针的指向</em></p>

<p><strong>方案1</strong>
先完成左子树的转换，链接中间节点后，再完成右子树的转换，然后链接中间节点和右子树</p>

<p><strong>方案2</strong>
中序遍历</p>

<p><strong>注</strong>
中序遍历的算法</p>

<h3>题目2</h3>

<p><em>定义栈的数据结构,要求添加一个 min 函数,能够得到栈的最小元素。要求函数 min、push 以及
pop 的时间复杂度都是 O(1)</em></p>

<p><strong>解析</strong></p>

<p><strong>方案</strong></p>

<p><strong>注</strong></p>

<h3>题目3</h3>

<p><em>输入一个整形数组,数组里有正数也有负数。数组中连续的一个或多个整数组成一个子数组,每个
子数组都有一个和。求所有子数组的和的最大值。要求时间复杂度为 O(n)</em></p>

<p><strong>解析</strong></p>

<p><strong>方案</strong></p>

<p><strong>注</strong></p>

<h3>题目4</h3>

<h3>题目11</h3>

<p><em>输入一颗二元查找树,将该树转换为它的镜像,即在转换后的二元查找树中,左子树的结点都大于
右子树的结点。用递归和循环两种方法完成树的镜像转换</em></p>

<p><strong>解析</strong></p>

<p>对于递归，类似递归遍历方式，在递归前交换左右子树；至于非递归，可以用循环可以用一个栈
来模拟递归操作。</p>

<h3>题目12</h3>

<p><em>输入一颗二元树,从上往下按层打印树的每个结点,同一层中按照从左往右的顺序打印</em></p>

<p><em>解析</em></p>

<p>就是用队列层次遍历</p>

<h3>题目13</h3>

<p><em>在一个字符串中找到第一个只出现一次的字符。如输入 abaccdeff,则输出 b</em></p>

<p><em>解析</em></p>

<p>简单来说O(n<sup>2)的依次比较。可以用哈希。类似的题目，找出相同的字符，相同字符</sup>
的次数，出现次数最多的字符。在一个巨大的文件内出现次数最多的k个成员等等</p>

<h3>题目14</h3>

<p><em>n 个数字(0,1,&#8230;,n-1)形成一个圆圈,从数字 0 开始,每次从这个圆圈中删除第 m 个数字(第一个
为当前数字本身,第二个为当前数字的下一个数字)
。当一个数字删除后,从被删除数字的下一个继续删除
第 m 个数字。求出在这个圆圈中剩下的最后一个数字</em></p>

<p><em>解析</em></p>

<p>约瑟夫问题，可以直接用stl::list模拟行为，然后直接操作。或者利用推导完成递归公式。</p>

<h3>题目15</h3>

<p>关于类中的深浅拷贝问题，需要自定义拷贝构造函数以及重载等号，另外为了避免指针
被外面别的类删除，可以考虑用引用计数的方式</p>

<h3>题目16</h3>

<p><em>用最快的方法求fibonacci数列的第 n 项</em></p>

<p><em>解析</em></p>

<p>由于递归会重复计算很多次相同的值，那么可以考虑从0到n的计算，这样可以省去重复的
次数，复杂度是o(n)</p>

<p>可以有利用数学归纳发发现log(n)的算法</p>

<h3>题目17</h3>

<p><em>输入一个表示整数的字符串,把该字符串转换成整数并输出。例如输入字符串&#8221;345&#8221;,则输出整数
345</em></p>

<p><em>解析</em></p>

<p>问题不难，在c/c++ java python中都有现成的方法，但是大都不够严谨全面。</p>

<p>可以考虑用一个全局变量来标识是否输入合法，标准c中的atoi就是这样做的。</p>

<h3>题目18</h3>

<p><em>-用两个栈实现队列</em></p>

<p><em>解析</em></p>

<p>一个栈出一个栈入，出栈非空一直出，空则将入栈内的数据导入其中</p>

<p><em>注</em></p>

<p>如何用两个队列实现一个栈，可以考虑n个数先入一个队列，一旦要出的话，将前n-1个都
出队，然后入队进另一个队列。每次操作都如此</p>

<h3>题目19</h3>

<p><em>输入一个链表的头结点,反转该链表,并返回反转后链表的头结点</em></p>

<p>需要保存反转节点的子节点</p>

<h3>题目20</h3>

<p><em>如果字符串一的所有字符按其在字符串中的顺序出现在另外一个字符串二中,则字符串一称之为字
符串二的子串。注意,并不要求子串(字符串一)的字符必须连续出现在字符串二中。请编写一个函数,
输入两个字符串,求它们的最长公共子串,并打印出最长公共子串。
例如:输入两个字符串 BDCABA 和 ABCBDAB,字符串 BCBA 和 BDAB 都是是它们的最长公共子串,则
输出它们的长度 4,并打印任意一个子串</em></p>

<p><em>解析</em></p>

<p>经典的动态规划问题。</p>

<h3>题目</h3>

<h2>参考</h2>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2012/08/08/mongodbquan-wei-zhi-nan-notes/">Mongodb权威指南 Notes</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2012-08-08T14:42:00+08:00" pubdate data-updated="true">Aug 8<span>th</span>, 2012</time>
        
         | <a href="/blog/2012/08/08/mongodbquan-wei-zhi-nan-notes/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h2>入门</h2>

<ul>
<li>文档是数据的基本单元</li>
<li>具有javascript shell</li>
<li>单个实例可以容纳多个独立数据库</li>
</ul>


<h3>文档</h3>

<p>javascript中文档表现为对象</p>

<p>区分类型且区分大小写</p>

<p>文档中不能有重复的键</p>

<h3>集合</h3>

<p>集合就是一组文档。</p>

<p>集合是无模式的</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2012/08/08/mongodb-simple/">MongoDB Simple</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2012-08-08T14:23:00+08:00" pubdate data-updated="true">Aug 8<span>th</span>, 2012</time>
        
         | <a href="/blog/2012/08/08/mongodb-simple/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h2>简介</h2>

<ul>
<li><p>拓展了关系数据库的功能，比如辅助索引，范围查询以及排序</p></li>
<li><p>内置MapReduce的支持</p></li>
<li><p>文档丰富，接口友好</p></li>
<li><p>MongoDB是一个面向文档的数据库。</p></li>
<li><p>没有模式</p></li>
<li><p>易于扩展</p></li>
<li><p>速度快</p></li>
<li><p>管理方便</p></li>
</ul>


<h2>简单安装和运行</h2>

<ol>
<li>直接下载二进制包</li>
<li>在根目录创建/data/db/目录</li>
<li>运行bin/mongod</li>
</ol>


<p>on Ubuntu</p>

<p>设置GPG key</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>sudo apt-key adv --keyserver keyserver.ubuntu.com --recv 7F0CEB10
</span></code></pre></td></tr></table></div></figure>


<p>在/etc/apt/sources.list.d/中创建10gen.list添加如下行</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>deb http://downloads-distro.mongodb.org/repo/ubuntu-upstart dist 10gen
</span></code></pre></td></tr></table></div></figure>


<p>然后运行</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>sudo apt-get update
</span><span class='line'>sudo apt-get install mongodb-10gen
</span></code></pre></td></tr></table></div></figure>


<h2>设置</h2>

<p>配置文件在/etc/mongodb.conf</p>

<h2>教程</h2>

<p>在其官方网站<a href="http://www.mongodb.org/">Mongodb</a>上有一个Try it out的教程</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2012/08/07/slice-reading-0807/">Slice Reading 0807</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2012-08-07T18:04:00+08:00" pubdate data-updated="true">Aug 7<span>th</span>, 2012</time>
        
         | <a href="/blog/2012/08/07/slice-reading-0807/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h2>SPDY协议特点</h2>

<ul>
<li>多路复用，请求优化</li>
<li>服务器推送</li>
<li>HTTP头压缩</li>
<li>强制SSL</li>
</ul>


<p><a href="http://www.scriptlover.com/static/1739-spdy-web-%E5%89%8D%E7%AB%AF">SPYD</a></p>

<h2>WebSocket</h2>

<p>客户端在HTTP协议中加入特殊的tag，服务端识别后与其建立长链接，服务端可以通过该链接主动推送内容到客户端上。</p>

<h2>webdriver</h2>

<p><a href="http://www.infoq.com/cn/news/2011/06/selenium-arch">开源应用架构之​Selenium WebDriver（上)</a></p>

<p><a href="http://code.google.com/p/chromedriver/">ChromeDriver</a></p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2012/08/07/apache-mina-with-spring/">Apache Mina With Spring</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2012-08-07T14:12:00+08:00" pubdate data-updated="true">Aug 7<span>th</span>, 2012</time>
        
         | <a href="/blog/2012/08/07/apache-mina-with-spring/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content">
</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/blog/page/3/">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
    <a class="next" href="/">Newer &rarr;</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2012/09/17/chromeqi-dong-liu-cheng/">chrome启动流程</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/09/14/chrommiumru-he-xian-shi-wang-ye/">Chrommium如何显示网页</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/09/11/libeventshi-yong/">Libevent使用</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/09/06/chromeduo-jin-cheng-jia-gou-yue-du/">chrome多进程架构阅读</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/09/06/c-plus-plus-de-traitsji-zhu/">c++的Traits技术</a>
      </li>
    
  </ul>
</section>






  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2012 - windfire.cd -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'windfire-cd-comments';
      
        
        var disqus_script = 'count.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>







  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'http://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>

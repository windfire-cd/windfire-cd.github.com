---
layout: post
title: "Hadoop"
date: 2012-07-05 18:14
comments: true
categories: 
---

##简介

[Apache Hadoop][#refhadoop]是一个开源的基于集群的分布式处理大数据的计算框架。
它用于将一个机器处理的问题切分为若干提供存储和计算资源的机器共同处理的问题，对于集群来说，
集群中的任何机器都可能失效，它提供基于应用层的异常处理功能。

[Apache Hadoop][#refhadoop]项目分为三个子项目
 
- [Hadoop Common]


[#refhadoop]: http://hadoop.apache.org/

hadoop主要克隆了Google运行系统的框架，包括

- 文件系统HDFS
- 计算框架MapReduce
- 结构化数据处理HBase

基于此的其他开源项目

- Pig
- Zookeeper
- HIVE

大数据存储和访问

关系型数据库和MapReduce差异

**网格计算**

大规模分布式的主要问题是处理失效和错误


##MapReduce简介

一种用于数据处理的编程模型，本质是并行的
分为两个阶段

- Map
- Reduce


**分支化**

- map任务
- reduce任务

两种类型节点控制作业执行

- jobtracker
- tasktracker


**输入输出流**

[Apache Hadoop][#refhadoop] 提供了API允许除JAVA外语言运行MapReduce，



##分布式文件系统

###HDFS设计

特点

- 针对超大文件而设计的文件系统
- 流式数据访问
- 商用硬件

缺点

- 低延迟访问（如果需要低延迟HBase更好）
- 大量小文件
- 多用户写入，任意修改

###HDFS概念

**块**

- 默认64M

**名称节点和数据节点**

- 管理者  命名空间
- 工作者  定位块

命名空间损坏会造成系统失效，保证其可用有以下两种方式

1. 复制组成文件系统元数据的持久文件
2. 二级名称节点

**命令行接口**

- hadoop fs -help
- hadoop fs -copyFromLocal input/docs/qu.txt hdfs://localhost/user/tom/qu.txt
- md5 input/docs/qu.txt qu.copy.txt
- hadoop fs -mkdir books
- hadoop fs ls

接口

- Thrift
- libhdfs
- fuse
- webdav
- http
- ftp

**Java接口**

###数据流


##hadoop的I/O

###序列化

writable是MapReduce数据路径的核心。


**序列化框架**

###基于文件的数据结构

**SequenceFile**

key/value结构


**MapFile**

sorted SequenceFile



##MapReduce开发

大致流程

- 编写map, reduce函数
- 单元测试
- 运行驱动作业
- 集群运行
- 调试错误
- 调整性能

###配置环境

###单元测试

###本地运行

###集群运行

不需要修改，直接打包后运行

拥有网络观察界面

调试方法，日志解析方法

调优列表

- mapper数量
- reducer数量
- 是否利用combainer
- 中间值
- 自定义序列
- shuffle运行


###MapReduce工作流

高级语言

- Pig
- HIHV
- Cascading

##MapReduce工作原理

###运行作业

- 提交作业
- 作业初始化
- 任务分配
- 任务执行
- 进度状态更新
- 作业完成

###失败的处理

###作业调度

早期FIFO使用整个

后来优先级队列

Fair Scheduler

###shuffle和排序

shuffle-- 系统排序的过程

优化的关键

很多时候是MapReduce的核心

###任务的执行


